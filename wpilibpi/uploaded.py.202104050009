#!/usr/bin/env python3

# Copyright (c) FIRST and other WPILib contributors.
# Open Source Software; you can modify and/or share it under the terms of
# the WPILib BSD license file in the root directory of this project.

import json
import time
import sys
import numpy as np
import cv2

from cscore import CameraServer, VideoSource, UsbCamera, MjpegServer
from networktables import NetworkTables
from networktables.util import ntproperty

configFile = "/boot/frc.json"

class CameraConfig: pass

team = None
server = False
cameraConfigs = []
cameras = []

def parseError(str):
    """Report parse error."""
    print("config error in '" + configFile + "': " + str, file=sys.stderr)

def readCameraConfig(config):
    """Read single camera configuration."""
    cam = CameraConfig()

    # name
    try:
        cam.name = config["name"]
    except KeyError:
        parseError("could not read camera name")
        return False

    # path
    try:
        cam.path = config["path"]
    except KeyError:
        parseError("camera '{}': could not read path".format(cam.name))
        return False

    # stream properties
    cam.streamConfig = config.get("stream")

    cam.config = config

    cameraConfigs.append(cam)
    return True

def readConfig():
    """Read configuration file."""
    global team
    global server

    # parse file
    try:
        with open(configFile, "rt", encoding="utf-8") as f:
            j = json.load(f)
    except OSError as err:
        print("could not open '{}': {}".format(configFile, err), file=sys.stderr)
        return False

    # top level must be an object
    if not isinstance(j, dict):
        parseError("must be JSON object")
        return False

    # team number
    try:
        team = j["team"]
    except KeyError:
        parseError("could not read team number")
        return False

    # ntmode (optional)
    if "ntmode" in j:
        str = j["ntmode"]
        if str.lower() == "client":
            server = False
        elif str.lower() == "server":
            server = True
        else:
            parseError("could not understand ntmode value '{}'".format(str))

    # cameras
    try:
        cameras = j["cameras"]
    except KeyError:
        parseError("could not read cameras")
        return False
    for camera in cameras:
        if not readCameraConfig(camera):
            return False

    return True

def startCamera(config):
    """Start running the camera."""
    print("Starting camera '{}' on {}".format(config.name, config.path))
    inst = CameraServer.getInstance()
    camera = UsbCamera(config.name, config.path)
    server = inst.startAutomaticCapture(camera=camera, return_server=True)

    camera.setConfigJson(json.dumps(config.config))
    camera.setConnectionStrategy(VideoSource.ConnectionStrategy.kKeepOpen)

    if config.streamConfig is not None:
        server.setConfigJson(json.dumps(config.streamConfig))

    return camera

class PowerCellContour:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__hsv_threshold_hue = [25.899280575539567, 29.11573068569659]
        self.__hsv_threshold_saturation = [185.74640287769785, 255.0]
        self.__hsv_threshold_value = [137.80585700930783, 255.0]

        self.hsv_threshold_output = None

        self.__find_contours_input = self.hsv_threshold_output
        self.__find_contours_external_only = False

        self.find_contours_output = None

        self.__filter_contours_contours = self.find_contours_output
        self.__filter_contours_min_area = 30.0
        self.__filter_contours_min_perimeter = 30.0
        self.__filter_contours_min_width = 0.0
        self.__filter_contours_max_width = 1000.0
        self.__filter_contours_min_height = 0.0
        self.__filter_contours_max_height = 1000.0
        self.__filter_contours_solidity = [0, 100]
        self.__filter_contours_max_vertices = 1000000.0
        self.__filter_contours_min_vertices = 0.0
        self.__filter_contours_min_ratio = 0.0
        self.__filter_contours_max_ratio = 1000.0

        self.filter_contours_output = None


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step HSV_Threshold0:
        self.__hsv_threshold_input = source0
        (self.hsv_threshold_output) = self.__hsv_threshold(self.__hsv_threshold_input, self.__hsv_threshold_hue, self.__hsv_threshold_saturation, self.__hsv_threshold_value)

        # Step Find_Contours0:
        self.__find_contours_input = self.hsv_threshold_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)

        # Step Filter_Contours0:
        self.__filter_contours_contours = self.find_contours_output
        (self.filter_contours_output) = self.__filter_contours(self.__filter_contours_contours, self.__filter_contours_min_area, self.__filter_contours_min_perimeter, self.__filter_contours_min_width, self.__filter_contours_max_width, self.__filter_contours_min_height, self.__filter_contours_max_height, self.__filter_contours_solidity, self.__filter_contours_max_vertices, self.__filter_contours_min_vertices, self.__filter_contours_min_ratio, self.__filter_contours_max_ratio)


    @staticmethod
    def __hsv_threshold(input, hue, sat, val):
        """Segment an image based on hue, saturation, and value ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max value.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HSV)
        return cv2.inRange(out, (hue[0], sat[0], val[0]),  (hue[1], sat[1], val[1]))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        im2, contours, hierarchy =cv2.findContours(input, mode=mode, method=method)
        return contours

    @staticmethod
    def __filter_contours(input_contours, min_area, min_perimeter, min_width, max_width,
                        min_height, max_height, solidity, max_vertex_count, min_vertex_count,
                        min_ratio, max_ratio):
        """Filters out contours that do not meet certain criteria.
        Args:
            input_contours: Contours as a list of numpy.ndarray.
            min_area: The minimum area of a contour that will be kept.
            min_perimeter: The minimum perimeter of a contour that will be kept.
            min_width: Minimum width of a contour.
            max_width: MaxWidth maximum width.
            min_height: Minimum height.
            max_height: Maximimum height.
            solidity: The minimum and maximum solidity of a contour.
            min_vertex_count: Minimum vertex Count of the contours.
            max_vertex_count: Maximum vertex Count.
            min_ratio: Minimum ratio of width to height.
            max_ratio: Maximum ratio of width to height.
        Returns:
            Contours as a list of numpy.ndarray.
        """
        output = []
        for contour in input_contours:
            x,y,w,h = cv2.boundingRect(contour)
            if (w < min_width or w > max_width):
                continue
            if (h < min_height or h > max_height):
                continue
            area = cv2.contourArea(contour)
            if (area < min_area):
                continue
            if (cv2.arcLength(contour, True) < min_perimeter):
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / max(cv2.contourArea(hull),1)
            if (solid < solidity[0] or solid > solidity[1]):
                continue
            if (len(contour) < min_vertex_count or len(contour) > max_vertex_count):
                continue
            ratio = (float)(w) / h
            if (ratio < min_ratio or ratio > max_ratio):
                continue
            output.append(contour)
        return output

class VisionClient(object):
    pathID = ntproperty("/Vision/pathID", 0)

#   input file: A-blue-01.jpg
#   [0.30286738 0.         0.99999998]
#   [0.         0.05607476 0.99999991]
#   input file: A-red-01.jpg
#   [0.         0.99999998 0.67824772]
#   [0.         0.51046023 0.99999996]
#   input file: B-blue-01.jpg
#   [0.75358164 0.         0.99999997]
#   [0.16483515 0.         0.99999989]
#   input file: B-red-01.jpg
#   [0.36024844 0.99999998 0.        ]
#   [0.         0.6296296  0.99999995]

# [0.99999997 0.30481283 0.        ]
# [0.99999984 0.         0.04918032]
# 5.131806603814785e-05 0 A blue
# [0.         0.99999998 0.65972221]
# [0.         0.48611108 0.99999993]
# 0.0009360758683462161 1 A red
# [0.7333333  0.         0.99999996]
# [0.11764704 0.         0.9999998 ]
# 0.002636713286258535 2 B blue
# [0.         0.40134528 0.99999998]
# [0.99999992 0.         0.51219508]
# 0.015479816876894448 3 B red

def match_triangle(x,y):
    triangles = np.array([[[0.30481283,0.,1.], [0.,0.04918032,1.]],
                          [[0.,1.,0.65972221], [0.,0.48611108,1.]],
                          [[0.73333333,0.,1.], [0.11764704,0.,1.]],
                          [[0.40134528,1.,0.], [0.,0.51219508,1.]]])
    names = ('A blue','A red','B blue','B red')
    dist = 1.e8
    ind = -1
    for i in range(0,4):
        d = tri_distance(x,y,triangles[i,:,:])
        if d < dist:
            dist = d
            ind = i
    return dist, ind, names[ind]

def tri_distance(x,y,triangle):
    distance = 0
    for i in range(0,3):
        dist, ind = closest_point(x[i],y[i],triangle)
        distance = distance + dist
    return distance

def closest_point(x,y,triangle):
    dist = 1.e8
    ind = -1
    for i in range(0,3):
        d = np.power(x - triangle[0,i],2) + np.power(y - triangle[1,i],2)
        if d < dist:
            dist = d
            ind = i
    return dist, ind

def main():

    # read configuration
    if not readConfig():
        sys.exit(1)

    # start NetworkTables as client
    ip = "10.19.12.2"
    NetworkTables.initialize(server=ip)
    time.sleep(0.5)

    c = VisionClient()

    # start camera
    config = cameraConfigs[0]
    camera = startCamera(config)

    #width = config['width']
    #height = config['height']
    width = 720
    height = 480
    print(width, height)
    img = np.zeros([width, height, 3], dtype = np.uint8)

    CameraServer.getInstance().startAutomaticCapture()

    input_stream = CameraServer.getInstance().getVideo()
    output_stream = CameraServer.getInstance().putVideo('Processed', width, height)

    # Wait for NetworkTables to start
    time.sleep(0.5)
    counter = 0
    small = .00001

    while True:
        start_time = time.time()
        counter = counter + 1

        frame_time, input_img = input_stream.grabFrame(img)
        output_img = np.copy(input_img)

        # Notify output of error and skip iteration
        if frame_time == 0:
            output_stream.notifyError(input_stream.getError())
            continue

        pipe = PowerCellContour()
        pipe.process(output_img)
        contours = pipe.filter_contours_output

        count_c = 0
        for i in contours:
            #compute the center of the contour
            count_c = count_c + 1

        if count_c > 0:
            s = np.zeros([count_c])
            count_c = 0
            for c in contours:
               s[count_c] = cv2.contourArea(c)
               count_c = count_c + 1

            ind = np.argsort(s)
            count_c = max(count_c, 3)
            x = np.zeros(count_c).astype(int)
            y = np.zeros(count_c).astype(int)

            for i in range(0,count_c):
               M = cv2.moments(contours[ind[i]])
               x[i] = int(M["m10"] / max(M["m00"],.01))
               y[i] = int(M["m01"] / max(M["m00"],.01))
               # draw the contour and center of the shape on the image
               cv2.drawContours(output_img, contours[ind[i]], -1, (0, 255, 0), 2)
               cv2.circle(output_img, (x[i], y[i]), 7, (255, 255, 255), -1)
               cv2.putText(output_img, "center", (x[i] - 20, y[i] - 20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

            xm = (x - x.min()) / (x.max() - x.min() + small)
            ym = (y - y.min()) / (y.max() - y.min() + small)
            list, pathid, pathname = match_triangle(xm,ym)

            if counter%50 == 0:
                print('pathID', pathid)
                print('pathName',pathname)

            c.pathID = pathid

        else:
            cv2.putText(output_img, "NO CONTOURS", (360, 240),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

        processing_time = time.time() - start_time
        fps = 1 / processing_time
        cv2.putText(output_img, str(round(fps, 1)), (0, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255))
        output_stream.putFrame(output_img)
        #cv2.imwrite('processed_image-%d.jpg'%counter,output_img)
        #if counter > 5:
        #    exit()

main()
